{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9aff3-9915-4e00-a8fd-426ac9dae365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import editdistance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_cer(preds, labels, char_to_idx, blank_idx=0):\n",
    "    \"\"\"Compute Character Error Rate (CER) for CTC-based predictions.\n",
    "    \n",
    "    Args:\n",
    "        preds: Model outputs, shape (batch_size, seq_len, num_classes).\n",
    "        labels: Ground truth labels, shape (batch_size, seq_len) or (batch_size,).\n",
    "        char_to_idx: Dictionary mapping characters to indices.\n",
    "        blank_idx: Index of the blank token (default 0).\n",
    "    \n",
    "    Returns:\n",
    "        float: Average CER across the batch.\n",
    "    \"\"\"\n",
    "    idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
    "    idx_to_char[blank_idx] = ''\n",
    "    total_cer = 0\n",
    "    batch_size = preds.size(0)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        pred = preds[i].argmax(dim=1)\n",
    "        pred_str = ''.join(idx_to_char.get(idx.item(), '') for idx in pred if idx.item() != blank_idx)\n",
    "        \n",
    "        if labels.dim() == 2:\n",
    "            true_str = ''.join(idx_to_char.get(idx.item(), '') for idx in labels[i] if idx.item() != blank_idx)\n",
    "        else:\n",
    "            true_str = idx_to_char.get(labels[i].item(), '')\n",
    "        \n",
    "        cer = editdistance.eval(pred_str, true_str) / max(len(true_str), 1)  # Use editdistance.eval\n",
    "        total_cer += cer\n",
    "    \n",
    "    return total_cer / batch_size\n",
    "\n",
    "def compute_wer(preds, labels, char_to_idx, blank_idx=0):\n",
    "    \"\"\"Compute Word Error Rate (WER). Treats each character sequence as a word.\n",
    "    \n",
    "    Args:\n",
    "        preds: Model outputs, shape (batch_size, seq_len, num_classes).\n",
    "        labels: Ground truth labels, shape (batch_size, seq_len) or (batch_size,).\n",
    "        char_to_idx: Dictionary mapping characters to indices.\n",
    "        blank_idx: Index of the blank token (default 0).\n",
    "    \n",
    "    Returns:\n",
    "        float: Average WER across the batch.\n",
    "    \"\"\"\n",
    "    idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
    "    idx_to_char[blank_idx] = ''\n",
    "    total_wer = 0\n",
    "    batch_size = preds.size(0)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        pred = preds[i].argmax(dim=1)\n",
    "        pred_str = ''.join(idx_to_char.get(idx.item(), '') for idx in pred if idx.item() != blank_idx)\n",
    "        \n",
    "        if labels.dim() == 2:\n",
    "            true_str = ''.join(idx_to_char.get(idx.item(), '') for idx in labels[i] if idx.item() != blank_idx)\n",
    "        else:\n",
    "            true_str = idx_to_char.get(labels[i].item(), '')\n",
    "        \n",
    "        wer = 1.0 if pred_str != true_str else 0.0\n",
    "        total_wer += wer\n",
    "    \n",
    "    return total_wer / batch_size\n",
    "\n",
    "def evaluate_hybrid(model, test_loader, char_to_idx, device):\n",
    "    \"\"\"Evaluate the HybridModel using CER, WER, and accuracy.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained HybridModel.\n",
    "        test_loader: DataLoader for test data.\n",
    "        char_to_idx: Dictionary mapping characters to indices.\n",
    "        device: Device to run evaluation on.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (CER, WER, accuracy).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_cer, total_wer, correct, total = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            print(f\"Evaluate HybridModel - Output shape: {outputs.shape}, Label shape: {labels.shape}\")\n",
    "            \n",
    "            outputs = F.log_softmax(outputs, dim=2)\n",
    "            total_cer += compute_cer(outputs, labels, char_to_idx, blank_idx=0)\n",
    "            total_wer += compute_wer(outputs, labels, char_to_idx, blank_idx=0)\n",
    "            \n",
    "            if labels.dim() == 1:\n",
    "                preds = outputs.argmax(dim=2)[:, 0]\n",
    "                correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    cer = total_cer / len(test_loader)\n",
    "    wer = total_wer / len(test_loader)\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return cer, wer, accuracy\n",
    "\n",
    "def evaluate_cnn(model, test_loader, char_to_idx, device):\n",
    "    \"\"\"Evaluate the CNNModel using accuracy.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained CNNModel.\n",
    "        test_loader: DataLoader for test data.\n",
    "        char_to_idx: Dictionary mapping characters to indices.\n",
    "        device: Device to run evaluation on.\n",
    "    \n",
    "    Returns:\n",
    "        float: Accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            print(f\"Evaluate CNNModel - Output shape: {outputs.shape}, Label shape: {labels.shape}\")\n",
    "            \n",
    "            if outputs.dim() == 1:\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_rnn(model, test_loader, char_to_idx, device):\n",
    "    \"\"\"Evaluate the RNNModel using CER, WER, and accuracy.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RNNModel.\n",
    "        test_loader: DataLoader for test data.\n",
    "        char_to_idx: Dictionary mapping characters to indices.\n",
    "        device: Device to run evaluation on.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (CER, WER, accuracy).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_cer, total_wer, correct, total = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            print(f\"Evaluate RNNModel - Output shape: {outputs.shape}, Label shape: {labels.shape}\")\n",
    "            \n",
    "            outputs = F.log_softmax(outputs, dim=2)\n",
    "            total_cer += compute_cer(outputs, labels, char_to_idx, blank_idx=0)\n",
    "            total_wer += compute_wer(outputs, labels, char_to_idx, blank_idx=0)\n",
    "            \n",
    "            if labels.dim() == 1:\n",
    "                preds = outputs.argmax(dim=2)[:, 0]\n",
    "                correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    cer = total_cer / len(test_loader)\n",
    "    wer = total_wer / len(test_loader)\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return cer, wer, accuracy\n",
    "\n",
    "def visualize_predictions(model, test_loader, char_to_idx, device, num_samples=5, save_path=\"outputs/visualizations/predictions.png\"):\n",
    "    \"\"\"Visualize model predictions on a batch of test data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model (HybridModel, CNNModel, or RNNModel).\n",
    "        test_loader: DataLoader for test data.\n",
    "        char_to_idx: Dictionary mapping characters to indices.\n",
    "        device: Device to run the model on.\n",
    "        num_samples: Number of samples to visualize (default: 5).\n",
    "        save_path: Path to save the visualization.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
    "    idx_to_char[0] = ''\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        images, labels = next(iter(test_loader))\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        if outputs.dim() == 3:\n",
    "            preds = outputs.argmax(dim=2)\n",
    "            pred_strings = [\n",
    "                ''.join(idx_to_char.get(idx.item(), '') for idx in pred if idx.item() != 0)\n",
    "                for pred in preds\n",
    "            ][:num_samples]\n",
    "        else:\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            pred_strings = [idx_to_char.get(pred.item(), '') for pred in preds][:num_samples]\n",
    "        \n",
    "        if labels.dim() == 2:\n",
    "            true_strings = [\n",
    "                ''.join(idx_to_char.get(idx.item(), '') for idx in label if idx.item() != 0)\n",
    "                for label in labels\n",
    "            ][:num_samples]\n",
    "        else:\n",
    "            true_strings = [idx_to_char.get(label.item(), '') for label in labels][:num_samples]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, min(num_samples, len(images)), figsize=(15, 5))\n",
    "        if num_samples == 1:\n",
    "            axes = [axes]\n",
    "        for i, ax in enumerate(axes):\n",
    "            img = images[i].cpu().numpy().transpose(1, 2, 0)\n",
    "            if img.shape[2] == 1:\n",
    "                img = img.squeeze(2)\n",
    "                ax.imshow(img, cmap=\"gray\")\n",
    "            else:\n",
    "                ax.imshow(img)\n",
    "            ax.set_title(f\"Pred: {pred_strings[i]}\\nTrue: {true_strings[i]}\")\n",
    "            ax.axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
